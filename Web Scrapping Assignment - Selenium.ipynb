{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83750dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\atul\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\atul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\atul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\atul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\atul\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\atul\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\atul\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b33fb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>expirence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Target</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tech Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka, Gurg...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka</td>\n",
       "      <td>Artech</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Brunel</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Celonis &amp; Salesforce Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Hitachi Energy</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Celonis &amp; Salesforce Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>HARMAN</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Aon</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>Aon</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "0                       Data Analyst   \n",
       "1                  Tech Data Analyst   \n",
       "2                       Data Analyst   \n",
       "3                       Data Analyst   \n",
       "4  Celonis & Salesforce Data Analyst   \n",
       "5  Celonis & Salesforce Data Analyst   \n",
       "6                       Data Analyst   \n",
       "7                       Data Analyst   \n",
       "8                       Data Analyst   \n",
       "9                       Data Analyst   \n",
       "\n",
       "                                            location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  Hybrid - Bangalore/ Bengaluru, Karnataka, Gurg...   \n",
       "2                    Bangalore/ Bengaluru, Karnataka   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                       Bangalore/Bengaluru, Chennai   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                       Hybrid - Bangalore/Bengaluru   \n",
       "7          Hybrid - Bangalore/Bengaluru, Delhi / NCR   \n",
       "8          Hybrid - Bangalore/Bengaluru, Delhi / NCR   \n",
       "9  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "\n",
       "                           company expirence  \n",
       "0                           Target   2-4 Yrs  \n",
       "1                            Wipro   3-6 Yrs  \n",
       "2                           Artech   5-8 Yrs  \n",
       "3                           Brunel   4-6 Yrs  \n",
       "4                   Hitachi Energy   3-6 Yrs  \n",
       "5                     Hitachi Ltd.   2-7 Yrs  \n",
       "6                           HARMAN   3-5 Yrs  \n",
       "7                              Aon   6-9 Yrs  \n",
       "8                              Aon   6-9 Yrs  \n",
       "9  Tata Consultancy Services (TCS)  5-10 Yrs  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "#Lets connect to the driver\n",
    "driver=webdriver.Chrome(r\"D:\\chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Opening naukri.com from chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "time.sleep(5)\n",
    "\n",
    "#Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "#Then click the searchbutton\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "#Then scrape the data for the first 10 jobs results you get.\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "expirence_required=[]\n",
    "\n",
    "#scrapping job title from teh given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scrapping job location from teh given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scrapping company name from teh given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scrapping expirence required from teh given page\n",
    "expirence_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in expirence_tags[0:10]:\n",
    "    expirence=i.text\n",
    "    expirence_required.append(expirence)\n",
    "    \n",
    "print(len(job_title),len(job_location),len(company_name),len(expirence_required))\n",
    "\n",
    "#Finally create a dataframe of the scraped data.\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'location':job_location,'company':company_name,'expirence':expirence_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3862667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Permanent Opportunity - Data Scientist(Snaplog...</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...</td>\n",
       "      <td>Deloitte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Persistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/ Bengaluru, Karnataka</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka, Hyde...</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Pune, Delhi / NC...</td>\n",
       "      <td>Infogain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Director/Senior Director - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Axtria India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manager/Senior Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Axtria India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Ericsson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Permanent Opportunity - Data Scientist(Snaplog...   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2                    Machine Learning (AI) Architect   \n",
       "3                               Staff Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                          Hiring For Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7            Director/Senior Director - Data Science   \n",
       "8              Manager/Senior Manager - Data Science   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            location  \\\n",
       "0  Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                    Bangalore/ Bengaluru, Karnataka   \n",
       "5  Hybrid - Bangalore/ Bengaluru, Karnataka, Hyde...   \n",
       "6  Hybrid - Bangalore/Bengaluru, Pune, Delhi / NC...   \n",
       "7  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "8  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                           company  \n",
       "0                         Deloitte  \n",
       "1                        Accenture  \n",
       "2                       Persistent  \n",
       "3                          Walmart  \n",
       "4  Tata Consultancy Services (TCS)  \n",
       "5  Tata Consultancy Services (TCS)  \n",
       "6                         Infogain  \n",
       "7                     Axtria India  \n",
       "8                     Axtria India  \n",
       "9                         Ericsson  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "#Lets connect to the driver\n",
    "driver=webdriver.Chrome(r\"D:\\chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Opening naukri.com from chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "time.sleep(5)\n",
    "\n",
    "#Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "#Then click the searchbutton\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "#Then scrape the data for the first 10 jobs results you get.\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "\n",
    "#scrapping job title from teh given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scrapping job location from teh given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scrapping company name from teh given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "print(len(job_title),len(job_location),len(company_name))\n",
    "\n",
    "#Finally create a dataframe of the scraped data.\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'location':job_location,'company':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcc7ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>expirence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Jubilant Ingrevia Limited</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python and ML Trainer</td>\n",
       "      <td>Hyderabad/Secunderabad, New Delhi, Pune, Gurga...</td>\n",
       "      <td>Thescholar</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Intern</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Tower Research Capital</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Assistant Manager</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>EXL</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Title                                           location  \\\n",
       "0   Junior Data Scientist  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "1          Data Scientist              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "2          Data Scientist                                              Noida   \n",
       "3          Data Scientist  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "4   Python and ML Trainer  Hyderabad/Secunderabad, New Delhi, Pune, Gurga...   \n",
       "5          Data Scientist                                        Delhi / NCR   \n",
       "6                  Intern                                   Gurgaon/Gurugram   \n",
       "7  Lead Assistant Manager                                   Gurgaon/Gurugram   \n",
       "8          Data Scientist                                              Noida   \n",
       "9   Junior Data Scientist    Gurgaon/Gurugram, United States (USA), Bulgaria   \n",
       "\n",
       "                           company expirence  \n",
       "0                         Analytos   0-2 Yrs  \n",
       "1                        Blackbuck   3-7 Yrs  \n",
       "2        Jubilant Ingrevia Limited   3-8 Yrs  \n",
       "3                         Analytos   2-4 Yrs  \n",
       "4                       Thescholar   3-8 Yrs  \n",
       "5  Tata Consultancy Services (TCS)  7-12 Yrs  \n",
       "6           Tower Research Capital   0-1 Yrs  \n",
       "7                              EXL   2-6 Yrs  \n",
       "8                       Innovaccer   2-4 Yrs  \n",
       "9                           Adidas   1-6 Yrs  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "#Lets connect to the driver\n",
    "driver=webdriver.Chrome(r\"D:\\chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Opening naukri.com from chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "time.sleep(5)\n",
    "\n",
    "#Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "#Then click the searchbutton\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Click on the location filter \"Delhi/NCR\"\n",
    "location_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/i\")\n",
    "location_filter.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Click on the salary filter \"3-6 lakhs\"\n",
    "salary_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "salary_filter.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#Then scrape the data for the first 10 jobs results you get.\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "expirence_required=[]\n",
    "\n",
    "#scrapping job title from teh given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scrapping job location from teh given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scrapping company name from teh given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scrapping expirence required from teh given page\n",
    "expirence_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in expirence_tags[0:10]:\n",
    "    expirence=i.text\n",
    "    expirence_required.append(expirence)\n",
    "    \n",
    "print(len(job_title),len(job_location),len(company_name),len(expirence_required))\n",
    "\n",
    "#Finally create a dataframe of the scraped data.\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'location':job_location,'company':company_name,'expirence':expirence_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a5ae6b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "#Lets connect to the driver\n",
    "driver=webdriver.Chrome(r\"D:\\chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Opening naukri.com from chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "time.sleep(5)\n",
    "\n",
    "#Close the login window\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#Enter “sunglasses” in the search field where “search for products, brands and more” is written\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys(\"sunglasses\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Click on search\n",
    "click_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "click_filter.click()\n",
    "time.sleep(5)\n",
    "\n",
    "brand_title=[]\n",
    "product_description=[]\n",
    "prise_tag=[]\n",
    "\n",
    "#scrapping brand from the given page\n",
    "\n",
    "for page in range(0,3):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tags:\n",
    "        if len(brand_title) == 100:\n",
    "            break\n",
    "        brand_title.append(i.text)\n",
    "    next_button=driver.find_elements(By.CLASS_NAME,'_1LKTO3')[-1]\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n",
    "    # Break the loop if we have scraped 100 brands\n",
    "    \n",
    "    \n",
    "#scrapping product description from the given page\n",
    "# Click on search\n",
    "click_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "click_filter.click()\n",
    "time.sleep(5)\n",
    "for page in range(0,3):\n",
    "    product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_tags:\n",
    "        if len(product_description) == 100:\n",
    "            break\n",
    "        product_description.append(i.text)\n",
    "    next_button=driver.find_elements(By.CLASS_NAME,'_1LKTO3')[-1]\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "#scrapping company name from the given page    \n",
    "# Click on search\n",
    "click_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "click_filter.click()\n",
    "time.sleep(5)\n",
    "for page in range(0,3):\n",
    "    prise_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in prise_tags:\n",
    "        if len(prise_tag) == 100:\n",
    "            break\n",
    "        prise_tag.append(i.text)\n",
    "    next_button=driver.find_elements(By.CLASS_NAME,'_1LKTO3')[-1]\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "\n",
    "    \n",
    "print(len(brand_title),len(product_description),len(prise_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d5bd4140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "#Lets connect to the driver\n",
    "driver=webdriver.Chrome(r\"D:\\chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Opening I Phone review from chrome browser\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")\n",
    "time.sleep(5)\n",
    "\n",
    "iphone_ratings=[]\n",
    "iphone_reviewsummary=[]\n",
    "iphone_fullreviews=[]\n",
    "\n",
    "# scraping first 100 reviews\n",
    "for page in range(0,15):\n",
    "    rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        if len(iphone_ratings) == 100:\n",
    "            break\n",
    "        iphone_ratings.append(i.text)\n",
    "    driver.find_elements(By.CLASS_NAME,'_1LKTO3')[-1].click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "# scraping first 100 reviews\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")\n",
    "time.sleep(5)\n",
    "for page in range(0,15):\n",
    "    review_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in review_tags:\n",
    "        if len(iphone_reviewsummary) == 100:\n",
    "            break\n",
    "        iphone_reviewsummary.append(i.text)\n",
    "    driver.find_elements(By.CLASS_NAME,'_1LKTO3')[-1].click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "# scraping first 100 reviews\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")\n",
    "time.sleep(5)\n",
    "for page in range(0,15):\n",
    "    fullreview_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in fullreview_tags:\n",
    "        if len(iphone_fullreviews) == 100:\n",
    "            break\n",
    "        iphone_fullreviews.append(i.text)\n",
    "    driver.find_elements(By.CLASS_NAME,'_1LKTO3')[-1].click()\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "print(len(iphone_ratings),len(iphone_reviewsummary),len(iphone_fullreviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a5002691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "#Lets connect to the driver\n",
    "driver=webdriver.Chrome(r\"D:\\chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Opening I Phone review from chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "time.sleep(5)\n",
    "\n",
    "#Close the login window\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "search.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#Enter “sneakers” in the search field where “search for products, brands and more” is written\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys(\"sneakers\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Click on search\n",
    "click_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "click_filter.click()\n",
    "time.sleep(5)\n",
    "\n",
    "brand_title=[]\n",
    "product_description=[]\n",
    "prise_tag=[]\n",
    "\n",
    "#scrapping brand from the given page\n",
    "\n",
    "for page in range(0,3):\n",
    "    brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tags:\n",
    "        if len(brand_title) == 100:\n",
    "            break\n",
    "        brand_title.append(i.text)\n",
    "    next_button=driver.find_elements(By.CLASS_NAME,'_1LKTO3')[-1]\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n",
    "    # Break the loop if we have scraped 100 brands\n",
    "    \n",
    "    \n",
    "#scrapping product description from the given page\n",
    "# Click on search\n",
    "click_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "click_filter.click()\n",
    "time.sleep(5)\n",
    "for page in range(0,3):\n",
    "    product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in product_tags:\n",
    "        if len(product_description) == 100:\n",
    "            break\n",
    "        product_description.append(i.text)\n",
    "    next_button=driver.find_elements(By.CLASS_NAME,'_1LKTO3')[-1]\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "#scrapping company name from the given page    \n",
    "# Click on search\n",
    "click_filter=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "click_filter.click()\n",
    "time.sleep(5)\n",
    "for page in range(0,3):\n",
    "    prise_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in prise_tags:\n",
    "        if len(prise_tag) == 100:\n",
    "            break\n",
    "        prise_tag.append(i.text)\n",
    "    next_button=driver.find_elements(By.CLASS_NAME,'_1LKTO3')[-1]\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "\n",
    "print(len(brand_title),len(product_description),len(prise_tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3fef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
